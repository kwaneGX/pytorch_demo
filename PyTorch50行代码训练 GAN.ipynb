{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n",
      "0: D: 0.691063165665/0.686793506145 G: 0.701174199581 (Real: [3.9950870293378831, 1.2356614089011166], Fake: [-0.054505770727992058, 0.0044457389694195328]) \n",
      "200: D: 0.000119991345855/0.391919463873 G: 1.16204273701 (Real: [3.9326510417461393, 1.1640190915093418], Fake: [-0.5267764574289322, 0.0030434676791221095]) \n",
      "400: D: 1.56165369845e-05/0.205167010427 G: 1.73255181313 (Real: [4.0690351414680483, 1.1693167008216907], Fake: [-0.51846747398376469, 0.016685837659340511]) \n",
      "600: D: 2.44379248215e-06/0.132327586412 G: 2.05526351929 (Real: [3.9627675354480743, 1.1342827197086673], Fake: [-0.37267209842801097, 0.12866760348650816]) \n",
      "800: D: 8.66689078975e-05/0.0955810174346 G: 3.0829308033 (Real: [4.0882653409242629, 1.3123023278361587], Fake: [0.066772003509104255, 0.57818001044180467]) \n",
      "1000: D: 0.0705448314548/0.0284459460527 G: 2.21662306786 (Real: [4.14647936463356, 1.1189794905600607], Fake: [1.9841053426265716, 0.70035788233641882]) \n",
      "1200: D: 0.102932155132/1.552475214 G: 1.15038025379 (Real: [4.1038736462593075, 1.2470310821334734], Fake: [3.7913664746284486, 0.87265516412076316]) \n",
      "1400: D: 0.622497260571/0.857741653919 G: 0.874866008759 (Real: [3.9941235077381134, 1.1823794009689794], Fake: [4.6069830870628357, 1.284049579367402]) \n",
      "1600: D: 0.830711007118/1.75592505932 G: 0.718166351318 (Real: [3.8877057498693466, 1.3304880995128814], Fake: [4.5854043483734133, 1.5340580721913644]) \n",
      "1800: D: 1.01647007465/0.955601871014 G: 0.382181763649 (Real: [4.1951119136810302, 1.2846761530019541], Fake: [5.2070645785331724, 1.3478505036633108]) \n",
      "2000: D: 0.762510180473/0.754386484623 G: 0.531712830067 (Real: [4.0666140645742415, 1.263676089049155], Fake: [5.1102931046485898, 1.5395859696398058]) \n",
      "2200: D: 0.473980158567/0.357000887394 G: 0.896781206131 (Real: [3.8655820441246034, 1.0739830245280331], Fake: [4.8219610548019407, 1.373591593954526]) \n",
      "2400: D: 0.683713138103/0.223627910018 G: 0.684778988361 (Real: [3.8268857845664024, 1.2450097204492003], Fake: [4.507831614017487, 1.2907423288869198]) \n",
      "2600: D: 0.758239865303/0.753448903561 G: 0.71817946434 (Real: [4.1344942581653594, 1.1603547618606198], Fake: [3.6085801559686659, 1.3060812904589261]) \n",
      "2800: D: 0.596725046635/0.574061214924 G: 0.650790810585 (Real: [3.8401901322603225, 1.2505342478074102], Fake: [3.4529160392284393, 1.0039465111285975]) \n",
      "3000: D: 0.55081230402/0.5151014328 G: 0.608836770058 (Real: [4.1856186413764958, 1.2569489295482548], Fake: [3.276394116282463, 1.1899445851294019]) \n",
      "3200: D: 0.65495544672/0.802139997482 G: 1.12732589245 (Real: [3.9785781264305116, 1.1742591747389624], Fake: [3.6370844304561616, 1.2683038546368386]) \n",
      "3400: D: 1.23626554012/0.715919673443 G: 0.651155292988 (Real: [3.8875167191028597, 1.019043933925686], Fake: [4.2242279815673829, 1.389826703697717]) \n",
      "3600: D: 0.688138544559/0.565821826458 G: 0.782631635666 (Real: [4.0885804247856141, 1.2794172793841456], Fake: [4.6965792095661163, 1.1018485577661916]) \n",
      "3800: D: 0.835920572281/0.559439063072 G: 0.35387134552 (Real: [4.0595190364122393, 1.2046973655386635], Fake: [3.8716890597343445, 1.4813166875481316]) \n",
      "4000: D: 0.698778688908/0.739231407642 G: 0.65008854866 (Real: [4.0599341666698452, 1.1689178573801295], Fake: [3.9939554917812345, 1.04650624283975]) \n",
      "4200: D: 0.252679884434/0.982847213745 G: 0.498291730881 (Real: [4.2320008814334873, 1.2238496971764272], Fake: [3.4848302549123762, 1.3877668337930891]) \n",
      "4400: D: 0.78110820055/0.587651193142 G: 0.610049545765 (Real: [3.7559701633453368, 1.0426610575449502], Fake: [4.2092020571231838, 1.2107655652224281]) \n",
      "4600: D: 0.727168738842/0.766283631325 G: 0.875408053398 (Real: [3.9885478740930558, 1.3068018481478569], Fake: [3.8218983012437819, 1.5275789839882552]) \n",
      "4800: D: 0.721409678459/0.611807584763 G: 1.03325212002 (Real: [4.0386959302425387, 1.2011767184017428], Fake: [4.1192576491832735, 1.2148233447340961]) \n",
      "5000: D: 0.832860827446/0.771007359028 G: 0.523955881596 (Real: [4.1206545400619508, 1.1710746844582125], Fake: [3.8424723339080811, 0.98490023626085488]) \n",
      "5200: D: 0.68308275938/0.604998111725 G: 0.686866641045 (Real: [3.8246270346641542, 1.1887812896917505], Fake: [3.3911431807279588, 1.3649664555080174]) \n",
      "5400: D: 1.29169154167/0.89880079031 G: 0.961925029755 (Real: [4.164990912675858, 1.0997444044937212], Fake: [4.242920535802841, 1.4919078233943388]) \n",
      "5600: D: 0.661036968231/0.546528816223 G: 0.525373995304 (Real: [4.0615929031372069, 1.2248716273718916], Fake: [4.1849621713161467, 1.3442253544266154]) \n",
      "5800: D: 0.517846047878/0.845821022987 G: 0.701698303223 (Real: [3.7917408349364994, 1.15541962258633], Fake: [3.6860927569866182, 1.324421582783242]) \n",
      "6000: D: 0.77267229557/0.661769390106 G: 0.659094393253 (Real: [4.1157592225074771, 1.3076101516102474], Fake: [3.6571724736690521, 1.2745123057103931]) \n",
      "6200: D: 0.671067476273/0.732839763165 G: 0.704226016998 (Real: [4.2092081031948325, 1.355771977278714], Fake: [3.9282183432579041, 1.4357531638174483]) \n",
      "6400: D: 0.975629031658/0.527194559574 G: 0.791209459305 (Real: [4.1306664836406704, 1.3322185184234829], Fake: [4.1209845626354218, 1.2621711064811547]) \n",
      "6600: D: 0.608631789684/0.739601314068 G: 0.782050549984 (Real: [4.1184714877605435, 1.188159826143439], Fake: [3.9547538638114927, 1.1099666772904759]) \n",
      "6800: D: 0.915798068047/0.572200596333 G: 0.951645076275 (Real: [3.7826100230216979, 1.2014048130749642], Fake: [3.9226981735229494, 1.4241675652660071]) \n",
      "7000: D: 0.77222263813/0.594395697117 G: 0.698449671268 (Real: [4.1626313221454616, 1.1829672043331823], Fake: [3.7201609295606612, 1.4914388601731665]) \n",
      "7200: D: 0.548201322556/1.03438365459 G: 0.676628887653 (Real: [3.9754204940795899, 1.3009381548399455], Fake: [3.6288496524095537, 1.198152738338266]) \n",
      "7400: D: 0.720039308071/0.660918712616 G: 0.410292446613 (Real: [3.779234539270401, 1.1779302761787329], Fake: [4.0434885716438291, 1.4301004965652619]) \n",
      "7600: D: 0.731418251991/0.865559577942 G: 0.706452548504 (Real: [4.062667132019997, 1.2175857404574615], Fake: [3.9795890212059022, 1.3033144851448126]) \n",
      "7800: D: 0.716474115849/0.823831558228 G: 0.657488703728 (Real: [3.870949946269393, 1.3417914216478453], Fake: [3.6835664439201357, 1.245896392502108]) \n",
      "8000: D: 0.69006973505/0.661156773567 G: 0.622469007969 (Real: [4.1393514764308925, 1.2358652723871502], Fake: [3.9533109569549563, 1.2525395235619512]) \n",
      "8200: D: 0.748638808727/0.62794983387 G: 0.823029696941 (Real: [3.9476866751909254, 1.2564893119775848], Fake: [3.9074819773435592, 1.2933187217598787]) \n",
      "8400: D: 0.747986376286/0.898996114731 G: 0.820441663265 (Real: [3.9167229652218523, 1.2534675625643348], Fake: [3.9205133998394013, 1.4736523021278385]) \n",
      "8600: D: 0.778955876827/0.623410642147 G: 0.714527308941 (Real: [3.835142771601677, 1.1856914787866608], Fake: [3.9954182958602904, 1.3834363734926516]) \n",
      "8800: D: 0.619533419609/0.644929587841 G: 0.839215695858 (Real: [4.3152421945333481, 1.331286116440981], Fake: [3.763704350590706, 1.2130484995438089]) \n",
      "9000: D: 1.00256967545/0.71323466301 G: 0.794997632504 (Real: [3.9668652713298798, 1.2448934668691496], Fake: [4.1405716824531558, 1.2351832075768785]) \n",
      "9200: D: 0.871715188026/0.691685259342 G: 0.668478429317 (Real: [3.9552795004844667, 1.2499046590713745], Fake: [4.2241718459129336, 1.0362178268783782]) \n",
      "9400: D: 0.43412822485/0.569027423859 G: 0.772882699966 (Real: [3.9229207503795624, 1.3703705121489567], Fake: [4.1290269541740416, 0.969191296346539]) \n",
      "9600: D: 0.442374199629/0.797065258026 G: 0.683252573013 (Real: [4.0325629034638402, 1.3824659121444485], Fake: [4.0368008697032929, 1.3390148628522047]) \n",
      "9800: D: 0.417881429195/0.879565179348 G: 0.844184219837 (Real: [3.7971022641658783, 1.2683355984826001], Fake: [3.6100619423389433, 1.4820988456168729]) \n",
      "10000: D: 0.692157030106/0.394740045071 G: 0.61148917675 (Real: [4.1027985537052158, 1.2596596364635391], Fake: [3.8230160880088806, 1.3798293085213493]) \n",
      "10200: D: 0.617451190948/0.731471717358 G: 0.580138623714 (Real: [4.0266045963764192, 1.4149245151035361], Fake: [4.1877270913124081, 1.1684312566733845]) \n",
      "10400: D: 0.535305678844/1.09238636494 G: 0.665709555149 (Real: [4.0534449756145481, 1.2363867701969908], Fake: [4.135726877450943, 1.2460316380690466]) \n",
      "10600: D: 0.436289310455/0.685129225254 G: 1.1962903738 (Real: [3.9122523927688597, 1.3039788393096696], Fake: [3.8498649692535398, 1.2098259489853653]) \n",
      "10800: D: 0.549943625927/0.799352884293 G: 0.786669075489 (Real: [4.0107128679752346, 1.0864825134206018], Fake: [3.9863369500637056, 1.3215342123840612]) \n",
      "11000: D: 0.371333152056/0.666027724743 G: 0.659722030163 (Real: [4.0888119876384739, 1.3285886414841088], Fake: [4.0938652265071873, 1.1315750240182727]) \n",
      "11200: D: 1.19697654247/0.386895209551 G: 0.886594831944 (Real: [3.9624490326642992, 1.4769027671657118], Fake: [3.9996749198436738, 1.0986976541210809]) \n",
      "11400: D: 0.831471562386/0.76427257061 G: 0.828646600246 (Real: [3.886169867515564, 1.1367076443880246], Fake: [4.087636938095093, 1.1868472964900967]) \n",
      "11600: D: 0.946770250797/0.451352924109 G: 0.810695886612 (Real: [4.1986494597792623, 1.4091295274344562], Fake: [3.9412588047981263, 1.2982663493955675]) \n",
      "11800: D: 0.947199940681/0.614825963974 G: 1.06553637981 (Real: [4.1549816143512723, 1.1083989885697694], Fake: [3.9516004550457002, 1.2638764102570528]) \n",
      "12000: D: 1.25258398056/0.434343039989 G: 0.62022793293 (Real: [3.9327621173858645, 1.2230535713007398], Fake: [4.1545200771093365, 1.23795655803811]) \n",
      "12200: D: 0.678841412067/0.598285734653 G: 0.886107087135 (Real: [4.2031799340248108, 1.1826202764505296], Fake: [3.8585511255264282, 1.3023060416491998]) \n",
      "12400: D: 0.937227845192/0.381288826466 G: 0.545824348927 (Real: [4.1475454235076903, 1.2299685028042273], Fake: [3.8533351117372514, 1.2730185585108706]) \n",
      "12600: D: 0.621612370014/1.05701887608 G: 1.3123499155 (Real: [3.8659223085641861, 1.1813263002830121], Fake: [3.8960337829589844, 1.3715033545351683]) \n",
      "12800: D: 0.520456135273/0.41247189045 G: 0.325370579958 (Real: [4.0884474438428882, 1.4668345974933912], Fake: [4.0203341233730319, 1.302487038940243]) \n",
      "13000: D: 0.412485212088/0.316957652569 G: 0.539176464081 (Real: [4.0024317163228993, 1.2519096997295216], Fake: [4.1391278249025341, 1.1185903826140746]) \n",
      "13200: D: 0.80888736248/0.4000210464 G: 1.01184904575 (Real: [3.9111287179589271, 1.2532157218280437], Fake: [4.2203237009048458, 1.2399492633767446]) \n",
      "13400: D: 0.448974698782/0.869430601597 G: 1.1307567358 (Real: [4.0879325306415559, 1.1983964915956611], Fake: [3.8110867863893509, 1.3354027651621563]) \n",
      "13600: D: 1.23637783527/0.319325983524 G: 0.678812503815 (Real: [4.0859817230701445, 1.2515584053860547], Fake: [3.9072180438041686, 1.1540830033401523]) \n",
      "13800: D: 0.524218142033/1.0136783123 G: 0.608522117138 (Real: [4.1308124607801435, 1.2679782512883737], Fake: [4.1495090425014496, 1.3679522632117882]) \n",
      "14000: D: 0.292705446482/0.416704595089 G: 0.646279990673 (Real: [3.9904583436250687, 1.3384448537107563], Fake: [4.2528754508495332, 1.2150002757459304]) \n",
      "14200: D: 0.685168921947/1.08641862869 G: 0.909319639206 (Real: [4.077463603019714, 1.2347340086322798], Fake: [3.7485100448131563, 1.2713299353799712]) \n",
      "14400: D: 0.543145418167/0.486722290516 G: 1.28411400318 (Real: [4.0494741320610048, 1.2586122594890938], Fake: [3.9396302688121794, 1.3076345396382771]) \n",
      "14600: D: 0.202484056354/0.285863369703 G: 1.26130926609 (Real: [4.1730200994014739, 1.2974130459000133], Fake: [4.0232354766130447, 1.2911993333974605]) \n",
      "14800: D: 0.380846560001/0.288078695536 G: 1.14958274364 (Real: [3.9062718087434769, 1.2217243367692181], Fake: [3.8665242326259612, 1.419211438262711]) \n",
      "15000: D: 0.760235786438/0.589404702187 G: 0.631708562374 (Real: [3.7408459210395812, 1.2160157524270465], Fake: [3.8696136772632599, 1.2574031618141661]) \n",
      "15200: D: 1.05157959461/0.359108567238 G: 0.595546245575 (Real: [3.9443319714069367, 1.1043165800274191], Fake: [4.1859187722206119, 1.1167793207940984]) \n",
      "15400: D: 0.877093613148/0.620568692684 G: 1.00068593025 (Real: [3.9631290203332901, 1.2095650217618554], Fake: [3.5576069307327272, 1.2779985751300087]) \n",
      "15600: D: 0.827551424503/0.445903807878 G: 1.22130131721 (Real: [3.9443683445453646, 1.3079174400655995], Fake: [4.0113741391897202, 1.3497667698904883]) \n",
      "15800: D: 0.529682159424/0.768781542778 G: 0.506810069084 (Real: [4.1438545361161232, 1.1707392624078705], Fake: [4.0321224874258039, 1.1614360441695388]) \n",
      "16000: D: 0.633269846439/0.464370340109 G: 0.459846109152 (Real: [3.9053125476837156, 1.1596528989999191], Fake: [4.0757530879974366, 1.1534246508118207]) \n",
      "16200: D: 0.654752612114/0.386539041996 G: 0.362000584602 (Real: [3.9707270634174345, 1.1622120821271578], Fake: [3.8358793354034422, 1.4454628891864156]) \n",
      "16400: D: 0.166342794895/0.336570173502 G: 1.12913489342 (Real: [4.2088070869445797, 1.2309790573716637], Fake: [4.2046126317977901, 1.2309180065211802]) \n",
      "16600: D: 0.650313556194/0.425856858492 G: 1.2071158886 (Real: [4.0386685782670977, 1.2384799686753816], Fake: [3.7276382923126219, 1.3663924801339107]) \n",
      "16800: D: 0.257383316755/0.649956643581 G: 1.40053546429 (Real: [4.0423406028747557, 1.231350648767265], Fake: [3.9667506593465807, 1.2693564262288195]) \n",
      "17000: D: 0.460883677006/0.368542701006 G: 1.76300358772 (Real: [4.1910449433326722, 1.3168066639339016], Fake: [3.9647417914867402, 1.3857842277339056]) \n",
      "17200: D: 0.364240348339/0.632569730282 G: 0.492765247822 (Real: [3.8849513149261474, 1.1816045366036163], Fake: [3.9590513634681703, 1.2136069101763778]) \n",
      "17400: D: 0.221446245909/0.17130485177 G: 1.34002876282 (Real: [3.8524451297521591, 1.2615791597731481], Fake: [4.1630765771865841, 1.1926687923114534]) \n",
      "17600: D: 0.253548800945/0.645211279392 G: 1.13302707672 (Real: [3.7977956879138945, 1.0198351325763864], Fake: [4.1208956289291381, 1.2169506634209835]) \n",
      "17800: D: 0.324145436287/0.3292337358 G: 0.492713242769 (Real: [4.049669979810715, 1.1765450138888809], Fake: [3.9567775523662565, 1.2150524463839194]) \n",
      "18000: D: 0.589325249195/0.488108575344 G: 1.13411200047 (Real: [3.8835287263989446, 1.3525235726954754], Fake: [3.9844338369369505, 1.1271900711813658]) \n",
      "18200: D: 0.0553616508842/0.216961473227 G: 0.660518229008 (Real: [3.9190208590030671, 1.2602197290407666], Fake: [3.9153880906105041, 1.233928901749455]) \n",
      "18400: D: 0.044897146523/0.707588255405 G: 0.803732097149 (Real: [4.0490871366858485, 1.2096807456791121], Fake: [4.2918688482046123, 1.1776612870015108]) \n",
      "18600: D: 0.0997356697917/0.255727469921 G: 0.751946568489 (Real: [3.9332717627286913, 1.2785791300953857], Fake: [3.9816780507564546, 1.2553491760375806]) \n",
      "18800: D: 0.472018957138/0.167502269149 G: 1.87069821358 (Real: [4.0520409476757049, 1.2314583126322796], Fake: [4.1924873089790342, 1.1365061131618814]) \n",
      "19000: D: 0.402615725994/0.343112230301 G: 0.719248890877 (Real: [4.1725237444043159, 1.2575368824781838], Fake: [4.1951754951477049, 1.1358566132829073]) \n",
      "19200: D: 1.59314155579/0.587813675404 G: 1.44023346901 (Real: [4.2113244414329527, 1.1864405104671796], Fake: [4.131618382930756, 1.2289283394591448]) \n",
      "19400: D: 0.756753742695/0.549940824509 G: 0.420720398426 (Real: [3.9583145302534102, 1.2445205785045843], Fake: [3.8213587003946303, 1.302820130614158]) \n",
      "19600: D: 1.44379794598/0.21558073163 G: 1.90403580666 (Real: [3.9793373894691468, 1.2062657357137223], Fake: [3.8672894895076753, 1.2815443165661433]) \n",
      "19800: D: 0.510004878044/0.354520946741 G: 0.62999099493 (Real: [3.7196130144596098, 1.2142854526291331], Fake: [3.9367557120323182, 1.3112121322268813]) \n",
      "20000: D: 0.208024948835/0.242400869727 G: 0.722486078739 (Real: [4.1403936064243316, 1.2143815260997739], Fake: [3.7733079242706298, 1.2150120414641519]) \n",
      "20200: D: 0.309608131647/0.347113311291 G: 1.04072082043 (Real: [4.0402115446329114, 1.2945310572452688], Fake: [4.212499551773071, 1.0934668094148599]) \n",
      "20400: D: 0.190317124128/0.379252821207 G: 1.32459640503 (Real: [4.0669748997688293, 1.1279096507264452], Fake: [4.0279395478963851, 1.1121927097660544]) \n",
      "20600: D: 0.0192049909383/0.371776819229 G: 1.28315770626 (Real: [4.3103166759014133, 1.2619285968582985], Fake: [3.8020789092779159, 1.3226948636175997]) \n",
      "20800: D: 0.164075091481/0.486225813627 G: 0.618143260479 (Real: [3.8808041775226592, 1.2379766477317136], Fake: [4.1515509724617008, 1.2048237434868614]) \n",
      "21000: D: 0.0752591341734/0.32346445322 G: 2.22279667854 (Real: [4.1113062894344328, 1.2398276245721551], Fake: [4.1565066176652907, 1.2809591673719174]) \n",
      "21200: D: 1.02692556381/0.149491161108 G: 1.41563951969 (Real: [3.9561345350742338, 1.277005214329167], Fake: [3.9279343688488009, 1.404013592186953]) \n",
      "21400: D: 0.454832196236/0.457856029272 G: 0.364119023085 (Real: [4.0001876348257062, 1.3322427425198349], Fake: [4.1705003392696378, 1.0638684457160243]) \n",
      "21600: D: 0.690388679504/0.457465410233 G: 1.69263970852 (Real: [4.1911869233846666, 1.2766126320728448], Fake: [4.1997017180919647, 1.4116632417847026]) \n",
      "21800: D: 0.413501352072/0.210974782705 G: 1.48798620701 (Real: [3.9312301012873649, 1.292891715396], Fake: [4.167890293598175, 1.2155817719266016]) \n",
      "22000: D: 0.182254210114/0.383072644472 G: 0.647435247898 (Real: [4.2353215312957762, 1.1545391529700628], Fake: [4.5214817774295808, 1.1877346948926557]) \n",
      "22200: D: 0.159361064434/0.170540183783 G: 2.44571423531 (Real: [3.8801219546794892, 1.2448370155371649], Fake: [4.1303795039653775, 1.2313385895614435]) \n",
      "22400: D: 0.211341544986/0.188609823585 G: 0.917189896107 (Real: [4.0760620805621146, 1.2533530543211164], Fake: [4.1813616460561756, 1.2543934553480558]) \n",
      "22600: D: 0.362382769585/0.0284029059112 G: 1.51438224316 (Real: [3.9020478481054308, 1.3228308393581387], Fake: [4.0547518640756604, 1.3868543605726691]) \n",
      "22800: D: 0.821651220322/0.337142556906 G: 1.5739634037 (Real: [4.0405826127529147, 1.0835735878604871], Fake: [4.3424609255790712, 1.1709123433149791]) \n",
      "23000: D: 0.071341343224/0.155299291015 G: 1.20329248905 (Real: [3.9650111186504362, 1.3312762943599952], Fake: [4.272654445171356, 1.2221433171167011]) \n",
      "23200: D: 1.75889575481/0.265615135431 G: 1.41254663467 (Real: [4.3400571703910824, 1.0258684121829309], Fake: [3.70854455024004, 1.3774283587756366]) \n",
      "23400: D: 0.426303952932/0.278068989515 G: 1.27459788322 (Real: [3.9436660730838775, 1.2211979329225644], Fake: [4.2884236341714859, 1.1461645067154662]) \n",
      "23600: D: 0.687869906425/0.275448948145 G: 2.83903622627 (Real: [3.930259249806404, 1.2185794043414289], Fake: [4.3538019168376927, 1.3794505213723209]) \n",
      "23800: D: 0.0567390955985/0.125320076942 G: 1.97571563721 (Real: [4.1155366462469098, 1.1835565545968185], Fake: [4.5628835737705229, 1.1623721060692858]) \n",
      "24000: D: 0.168271064758/0.529787063599 G: 2.54212594032 (Real: [3.8344660723209381, 1.2145601943000126], Fake: [4.3285050809383394, 1.2344836140730699]) \n",
      "24200: D: 0.187622994184/0.498884052038 G: 1.00164794922 (Real: [4.0758361649513244, 1.2031609962831007], Fake: [4.0070563793182377, 1.2234204782509366]) \n",
      "24400: D: 1.43598341942/0.390830099583 G: 2.31185889244 (Real: [3.9502536273002624, 1.3839396118457887], Fake: [3.9574276453256605, 1.3479881850745152]) \n",
      "24600: D: 1.27019679546/0.586961269379 G: 1.70339918137 (Real: [3.9545706218481063, 1.2674437981256856], Fake: [4.0368983447551727, 1.2829118855533486]) \n",
      "24800: D: 0.239576339722/0.28394022584 G: 1.02981197834 (Real: [4.1695866328477855, 1.2661615522975223], Fake: [3.9796475648880003, 1.2860770793950542]) \n",
      "25000: D: 0.321864068508/0.647933483124 G: 0.762871801853 (Real: [4.0952378165721894, 1.2547281387046716], Fake: [4.1828421974182133, 1.2698722243964196]) \n",
      "25200: D: 0.240347668529/0.185707733035 G: 1.20956861973 (Real: [4.0702698147296905, 1.2563695058273248], Fake: [4.2239891147613529, 1.4006451085477196]) \n",
      "25400: D: 0.345871180296/0.401225239038 G: 0.64227181673 (Real: [4.2740294671058656, 1.3075875667369654], Fake: [4.3739372026920318, 1.3388152525146866]) \n",
      "25600: D: 0.060171470046/0.284828811884 G: 0.839066445827 (Real: [3.9804983675479888, 1.3022327811429188], Fake: [3.9925496089458465, 1.3883159814522732]) \n",
      "25800: D: 0.480144947767/0.238540351391 G: 2.3360452652 (Real: [3.7301764373481272, 1.2504536241423105], Fake: [4.0633200967311858, 1.2295774464969225]) \n",
      "26000: D: 0.140634670854/0.927956163883 G: 0.574252784252 (Real: [3.9357187753915785, 1.314087343399289], Fake: [4.1828494429588314, 1.2563846231907241]) \n",
      "26200: D: 0.128273874521/0.306868314743 G: 2.22027420998 (Real: [3.8183764410018921, 1.1579017941412879], Fake: [4.4947808659076687, 1.3512809732225635]) \n",
      "26400: D: 0.412334233522/0.228471547365 G: 0.658101439476 (Real: [3.9397728064656259, 1.34743574345683], Fake: [4.5685967254638671, 1.2203900896298194]) \n",
      "26600: D: 0.296822577715/0.23111397028 G: 2.94454050064 (Real: [4.1008758735656734, 1.3451567966493765], Fake: [4.8674015903472903, 1.5233995798442037]) \n",
      "26800: D: 0.095104560256/0.159731417894 G: 1.11440563202 (Real: [3.8519178703613579, 1.1819968652203476], Fake: [4.809453423023224, 1.1976117128879351]) \n",
      "27000: D: 0.267467767/0.584438562393 G: 1.38313281536 (Real: [3.9038382434099912, 1.1964007610693159], Fake: [4.418168709278107, 1.2889613106565627]) \n",
      "27200: D: 1.02931714058/0.594878554344 G: 0.335280388594 (Real: [3.982561414539814, 1.3341057714045987], Fake: [3.6185894894599913, 1.0321332003504737]) \n",
      "27400: D: 0.338207155466/2.51274085045 G: 1.21735060215 (Real: [4.0466025626659397, 1.2861504086363114], Fake: [3.1819092559814455, 1.0807293717661755]) \n",
      "27600: D: 0.705570280552/0.999977588654 G: 0.635989248753 (Real: [4.1410948598384856, 1.2909905446953109], Fake: [4.7708041548728941, 1.3494042057188138]) \n",
      "27800: D: 0.717389762402/0.466051220894 G: 1.04472672939 (Real: [3.9518156468868257, 1.2183366899359451], Fake: [4.5713303446769711, 1.146638369453667]) \n",
      "28000: D: 0.682153880596/1.16328394413 G: 0.681571602821 (Real: [4.0829469931125644, 1.0750376663666759], Fake: [3.723234577178955, 1.2746575158310567]) \n",
      "28200: D: 0.634780406952/0.654389560223 G: 0.729150414467 (Real: [4.1464837706089019, 1.1376463532574932], Fake: [3.4562193226814268, 1.0810426991508091]) \n",
      "28400: D: 0.773608446121/0.736673116684 G: 0.643700480461 (Real: [3.9993266582489015, 1.3904755426263506], Fake: [4.4254763293266297, 1.1850299359126921]) \n",
      "28600: D: 0.970907270908/0.761066675186 G: 0.731219410896 (Real: [4.087941378951073, 1.1657091771586361], Fake: [3.8519789576530457, 1.2416438642401908]) \n",
      "28800: D: 0.643247902393/0.757327079773 G: 0.567829310894 (Real: [3.9077938783168791, 1.2540308751007443], Fake: [3.4906329715251925, 1.0815474436165355]) \n",
      "29000: D: 0.799365520477/0.748474061489 G: 0.795966207981 (Real: [3.9506355571746825, 1.1807788424764361], Fake: [4.2547672629356388, 1.2677961673480369]) \n",
      "29200: D: 0.624954283237/0.886489331722 G: 0.596367537975 (Real: [3.9218248030543328, 1.3222636028665027], Fake: [3.560521079301834, 1.1101848658400488]) \n",
      "29400: D: 0.611233115196/0.827149093151 G: 0.762762069702 (Real: [4.1791737532615665, 1.2098430601924757], Fake: [4.3691858553886416, 1.173770498309086]) \n",
      "29600: D: 0.658760070801/0.610235035419 G: 0.781085729599 (Real: [3.8223266553878785, 1.1731418715060611], Fake: [3.7738837778568266, 1.4136153531847027]) \n",
      "29800: D: 0.651105344296/0.606151580811 G: 0.838860988617 (Real: [4.2238301479816434, 1.2272263738763449], Fake: [4.4098418807983402, 1.6476157855522089]) \n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Generative Adversarial Networks (GAN) example in PyTorch.\n",
    "# See related blog post at https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f#.sch4xgsa9\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1\n",
    "\n",
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))\n",
    "\n",
    "# ##### R,原始数据 DATA: Target data and generator input data\n",
    "\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "# ##### I：\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
    "\n",
    "# ##### G：MODELS: Generator model and discriminator model\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "# ##### D：\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n",
    "\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
